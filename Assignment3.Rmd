---
title: "BME4550_Fall2018_Assignment3"
author: "Monika Grabowska"
date: "September 18, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(nycflights13)
```

## 11.2.2 Exercises

###1. What function would you use to read a file where fields were separated with “|”?

The `read_delim()` function with the argument `delim = "|"`. 

```
read_delim(file, delim = "|")
```

###2. Apart from `file`, `skip`, and `comment`, what other arguments do `read_csv()` and `read_tsv()` have in common?

`read_csv()` and `read_tsv()` have all of the same arguments as they are both special cases of `read_delim()`. These arguments include `col_names`, `col_types`, `locale`, `na`, `quoted_na`, `quote`, `comment`, `trim_ws`, `skip`, `n_max`, `guess_max`, and `progress`. 

###3. What are the most important arguments to `read_fwf()?`

The most important argument to `read_fwf()` is `col_positions` (defines where the data columns begin and end). 

###4. Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like `"` or `'`. By convention, `read_csv()` assumes that the quoting character will be `"`, and if you want to change it you’ll need to use `read_delim()` instead. What arguments do you need to specify to read the following text into a data frame?

```
"x,y\n1,'a,b'"
```

```{r}
read_delim("x,y\n1,'a,b'", delim = ",",  quote = "'")
```

###5. Identify what is wrong with each of the following inline CSV files. What happens when you run the code?

```{r, error = TRUE}
read_csv("a,b\n1,2,3\n4,5,6")
```

Only 2 column headers are given (`a` and `b`), but there are 3 columns in the rows. When you run the code, the values in the third column are dropped. 

```{r}
read_csv("a,b,c\n1,2\n1,2,3,4")
```

3 column headers are given (`a`, `b`, and `c`), but there are only 2 columns in the first row and there are 4 columns in the last row. When you run the code, there is a missing (`NA`) value in the third column of the first row and the value in the fourth column of the last row is dropped. 

```{r}
read_csv("a,b\n\"1")
```

There is no closing quote around the 1, thus the quote preceding the 1 is dropped when you run the code (and thus `a` is treated like an integer). There is a missing (`NA`) value in the first row of the `b` column. 

```{r}
read_csv("a,b\n1,2\na,b")
```

When you run the code, `a` and `b` are both treated as character vectors since the second row contains non-numeric strings. 

```{r}
read_csv("a;b\n1;3")
```

When you run the code, `a;b` is treated as one column header and `1:3` is treated as one value within that column (`read_csv` looks for commas rather than semi-colons). 

## 11.3.5 Exercises

###1. What are the most important arguments to `locale()`?

`encoding` is the most important argument to `locale()` since it affects how files are read. `decimal_mark` and `grouping_mark` are also important as they define the symbols used to indicate the decimal place/to chunk larger numbers. 

###2. What happens if you try and set `decimal_mark` and `grouping_mark` to the same character? What happens to the default value of `grouping_mark` when you set `decimal_mark` to “,”? What happens to the default value of `decimal_mark` when you set the `grouping_mark` to “.”?

```{r, error = TRUE}
locale(decimal_mark = ".", grouping_mark = ".")
```

If `decimal_mark` and `grouping_mark` are set to the same character, then you get an error.

```{r}
locale(decimal_mark = ",")
```

If `decimal_mark` is set to "," then `grouping_mark` is set to ".".

```{r}
locale(grouping_mark = ".")
```

If `grouping_mark` is set to "." then `decimal_mark` is set to ",".

###3. I didn’t discuss the `date_format` and `time_format` options to `locale()`. What do they do? Construct an example that shows when they might be useful.

`date_format` and `time_format` define the default data and time formats, which are used by functions such as `parse_date()` and `parse_time()`. 

Examples:
```{r}
parse_date("01/02/15", locale = locale(date_format = "%d/%m/%y"))
parse_time("02-00-08 am", locale = locale(time_format = "%M-%S-%I %p"))
```

###4. If you live outside the US, create a new locale object that encapsulates the settings for the types of file you read most commonly.

Not applicable.

###5. What’s the difference between `read_csv()` and `read_csv2()`?

`read_csv()` uses a comma as the delimiter, whereas `read_csv2()` uses a semi-colon as the delimiter.

###6. What are the most common encodings used in Europe? What are the most common encodings used in Asia? Do some googling to find out.

Europe: ISO 8859-1, ISO 8859-2, ISO 8859-3, etc...

Asia: Big5, GB 2312, EUC-KR, EUC-JP, etc...

###7. Generate the correct format string to parse each of the following dates and times:

```{r}
d1 <- "January 1, 2010"
d2 <- "2015-Mar-07"
d3 <- "06-Jun-2017"
d4 <- c("August 19 (2015)", "July 1 (2015)")
d5 <- "12/30/14" # Dec 30, 2014
t1 <- "1705"
t2 <- "11:15:10.12 PM"

parse_date(d1, "%B %d, %Y")
parse_date(d2, "%Y-%b-%d")
parse_date(d3, "%d-%b-%Y")
parse_date(d4, "%B %d (%Y)")
parse_date(d5, "%m/%d/%y")
parse_time(t1, "%H%M")
parse_time(t2, "%H:%M:%OS %p")
```

## 12.2.1 Exercises

###1. Using prose, describe how the variables and observations are organised in each of the sample tables.

```{r}
table1
```

In table1, each variable (`country`, `year`, `cases`, `population`) has its own column and each observation has its own row. 

```{r}
table2
```

In table2, each row is defined by `country`, `year`, `type` ("cases" or "population"), and `count`.

```{r}
table3
```

In table3, each row is defined by `country`, `year`, and `rate` (where `rate` is the number of cases divided by the population count as a character string). 

```{r}
table4a
table4b
```

Table 4 is spread across two tibbles, table4a for cases and table4b for population. Within each table, each row is defined by `country` and the number of cases or the population count for the year `1999` and the year `2000`.

###2. Compute the `rate` for `table2`, and `table4a` + `table4b`. You will need to perform four operations: 1) Extract the number of TB cases per country per year. 2) Extract the matching population per country per year. 3) Divide cases by population, and multiply by 10000. 4) Store back in the appropriate place. Which representation is easiest to work with? Which is hardest? Why?

For `table2`:
```{r}
countries <- filter(table2, type == 'cases')$country
years <- filter(table2, type == 'cases')$year
count_cases <- filter(table2, type == 'cases')$count
count_population <- filter(table2, type == 'population')$count
rate = count_cases/count_population * 1000
tibble(country = countries, year = years, rate = rate)
```

For `table4a` + `table4b`:
```{r}
countries <- table4a$country
cases_1999 <- table4a$`1999`
cases_2000 <- table4a$`2000`
population_1999 <- table4b$`1999`
population_2000 <- table4b$`2000`
rate_1999 <- tibble(country = countries, year = 1999, rate = cases_1999 / population_1999 * 10000)
rate_2000 <- tibble(country = countries, year = 2000, rate = cases_2000 / population_2000 * 10000)
(table4_rate <- rbind(rate_1999, rate_2000) %>% arrange(country))
```

`table2` is easier to work with since all of the data is in one table. 

###3. Recreate the plot showing change in cases over time using `table2` instead of `table1`. What do you need to do first?

First need to filter `table2` to have rows with `type` == `cases` only.

```{r}
table2_cases = filter(table2, type == "cases")
ggplot(data = table2_cases, aes(year, count)) +
  geom_line(aes(group = country), colour = "grey50") +
  geom_point(aes(color = country)) 
```

## 12.3.3 Exercises

###1. Why are `gather()` and `spread()` not perfectly symmetrical? Carefully consider the following example:

```{r}
(stocks <- tibble(
  year   = c(2015, 2015, 2016, 2016),
  half  = c(   1,    2,     1,    2),
  return = c(1.88, 0.59, 0.92, 0.17)
))
stocks %>% 
  spread(year, return) %>% 
  gather("year", "return", `2015`:`2016`)
```

### (Hint: look at the variable types and think about column names.) Both `spread()` and `gather()` have a `convert` argument. What does it do?

`spread()` and `gather()` are not perfectly symmetrical because information about column types is not transferred between them. In the example above, after running `spread()` and `gather()`, the `year` column changes from type `dbl` to type `chr`. This is because after running `spread()`, `2015` and `2016` become column names, which are then treated as strings when using `gather()`. 

###2. Why does this code fail?

```{r, error = TRUE}
table4a %>% 
  gather(1999, 2000, key = "year", value = "cases")
```

This code fails because 1999 and 2000 need to be in quotes (since they refer to names of columns in table4a rather than the 1999th and 2000th columns of table4a). 

```{r}
table4a %>% 
  gather(`1999`, `2000`, key = "year", value = "cases")
```

###3. Why does spreading this tibble fail? How could you add a new column to fix the problem?

```{r, error = TRUE}
people <- tribble(
  ~name,             ~key,    ~value,
  #-----------------|--------|------
  "Phillip Woods",   "age",       45,
  "Phillip Woods",   "height",   186,
  "Phillip Woods",   "age",       50,
  "Jessica Cordero", "age",       37,
  "Jessica Cordero", "height",   156
)

spread(people, key, value)
```

Spreading this tibble fails because both the first and third rows contain a different value for "age" of "Phillip Woods". A new column with the number of the observation could be added to fix the problem, as shown below. 

```{r}
people <- tribble(
  ~name,             ~key,    ~value, ~obs_num,
  #-----------------|--------|------|------
  "Phillip Woods",   "age",       45, 1,
  "Phillip Woods",   "height",   186, 1,
  "Phillip Woods",   "age",       50, 2,
  "Jessica Cordero", "age",       37, 1,
  "Jessica Cordero", "height",   156, 1
)

spread(people, key, value)
```

###4. Tidy the simple tibble below. Do you need to spread or gather it? What are the variables?

```{r}
preg <- tribble(
  ~pregnant, ~male, ~female,
  "yes",     NA,    10,
  "no",      20,    12
)
```

The tibble needs to be gathered. The variables are sex (male or female), pregnant (yes or no), and count. 

```{r}
preg %>%
  gather(male, female, key = "sex", value = "count", na.rm = TRUE)
```

## 12.4.3 Exercises

###1. What do the `extra` and `fill` arguments do in `separate()`? Experiment with the various options for the following two toy datasets.

```{r}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"))

tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("one", "two", "three"))
```

The `extra` argument in `separate()` controls what happens when there are too many pieces. The default behavior is to emit a warning and drop extra values (`warn`). Alternative options are to drop any extra values without a warning (`drop`) or to split the extra values (`merge`).

```{r}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"), extra = "drop")

tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"), extra = "merge")
```

The `fill` argument in `separate()` controls what happens when there are not enough pieces. The default behavior is to emit a warning and fill from the right (`warn`). Alternative options are to fill with missing values on the right (`right`) or to fill with missing values on the left (`left`). 

```{r}
tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("one", "two", "three"), fill = "right")
```

```{r}
tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("one", "two", "three"), fill = "left")
```

###2. Both `unite()` and `separate()` have a `remove` argument. What does it do? Why would you set it to `FALSE`?

If set to `TRUE`, the `remove` argument in `unite()` and `separate()`removes the input column from the output data frame. You would set it to `FALSE` if you want to create a new variable while keeping the old variable. 

```{r}
table1 %>% 
  separate(year, into = c("century", "year_2"), sep = 2, remove = TRUE)
```

```{r}
table1 %>% 
  separate(year, into = c("century", "year_2"), sep = 2, remove = FALSE)
```

With `remove = TRUE`, `year` is removed from the data frame; with `remove = FALSE`, `year` remains in the data frame. 

###3. Compare and contrast `separate()` and `extract()`. Why are there three variations of separation (by position, by separator, and with groups), but only one unite?

`extract()` uses regular expression to capture groups and turn each group into a new column. `separate()` uses either regular expression or a vector of character positions to turn a single character column into multiple columns. While there are several ways to separate a column into multiple columns, there is only way to put together multiple columns into a single column, thus it makes sense that there are 3 variations of separation but only one unite. 

## 12.5.1 Exercises

###1. Compare and contrast the `fill` arguments to `spread()` and `complete()`.

If `fill` is set in `spread()`, all explicit missing values (i.e. NA) and implicit missings (rows that aren't present) will be replaced by the fill value. In `complete()`, NAs under different variables can be replaced by different values. The `fill` argument in `complete()` takes in a list specifying the values with which to replace NA with for each variable, while the `fill` argument in `spread()` only takes in one value. 

###2. What does the `direction` argument to `fill()` do?

The `direction` argument to `fill()` specifies the direction in which to fill missing values. The default is "down" (any NAs will be replaced by the previous non-missing value) but it can also be set to "up".

## 12.6.1 Exercises

###1. In this case study I set `na.rm = TRUE` just to make it easier to check that we had the correct values. Is this reasonable? Think about how missing values are represented in this dataset. Are there implicit missing values? What’s the difference between an `NA` and `zero`?

```{r}
who %>%
  group_by(country) %>%
  summarize(year_min = min(year), year_max = max(year)) %>%
  ggplot() +
  geom_point(mapping = aes(x = year_min, y = country), color = 'red') +
  geom_point(mapping = aes(x = year_max , y= country), color = 'blue')
```

While most countries have data starting in 1980 and ending in 2013, there are implicit missing values, as shown by the plot above. 

```{r}
sum(who %>% select(-c(1:4)) == 0, na.rm = TRUE)
sum(who %>% select(-c(1:4)) %>% sapply(function(x){sum(is.na(x))}))
```

There are 11080 `zero` values (which indicate there were no cases of TB reported) and 329394 NA values. Setting `na.rm = TRUE` seems reasonable in this case. 

###2. What happens if you neglect the `mutate()` step? (`mutate(key = stringr::str_replace(key, "newrel", "new_rel"))`)

```{r, error = TRUE}
who %>%
  gather(new_sp_m014:newrel_f65, key = "key", value = "cases", na.rm = TRUE) %>%
  #mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
  separate(key, c("new", "type", "sexage"), sep = "_") %>%
  tail()
```

If you neglect the `mutate()` step, then the `sexage` column will have a value of NA for keys that began with "newrel".

###3. I claimed that `iso2` and `iso3` were redundant with country. Confirm this claim.

```{r}
select(who, country, iso2, iso3) %>%
  distinct() %>%
  group_by(country) %>%
  filter(n() > 1)
```

###4. For each country, year, and sex compute the total number of cases of TB. Make an informative visualisation of the data.

```{r}
who %>%
  gather(new_sp_m014:newrel_f65, key = "key", value = "cases", na.rm = TRUE) %>%
  mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
  separate(key, c("new", "type", "sexage"), sep = "_") %>%
  select(-new, -iso2, -iso3) %>%
  separate(sexage, c("sex", "age"), sep = 1) %>%
  group_by(country, year, sex) %>%
  summarise(cases = sum(cases)) %>%
  unite(country_sex, country, sex, remove = FALSE) %>%
  ggplot(aes(x = year, y = cases, group = country_sex, colour = sex)) +
  geom_line()
```

## 13.2.1 Exercises

###1. Imagine you wanted to draw (approximately) the route each plane flies from its origin to its destination. What variables would you need? What tables would you need to combine?

You would need to combine the `flights` and `airports` tables, as you would need to match the `dest` and `origin` variables from `flights` with the `faa` variable from `airports`. 

###2. I forgot to draw the relationship between `weather` and `airports`. What is the relationship and how should it appear in the diagram?

`weather` and `airports` can be matched using the variable `origin` in `weather` and the variable  `faa` in `airports`.

###3. `weather` only contains information for the origin (NYC) airports. If it contained weather records for all airports in the USA, what additional relation would it define with `flights`?

If it contained weather records for all airports in the USA, you could also connect `weather` with `flights` through `dest`. 

###4. We know that some days of the year are “special”, and fewer people than usual fly on them. How might you represent that data as a data frame? What would be the primary keys of that table? How would it connect to the existing tables?

You could create a table with columns for year, month, day, and holiday_name. The primary key would be the unique date (year, month, day combination) of the holiday, and you could connect the table to existing tables (for example, `flights` and `weather`) based on the date. 

## 13.3.1 Exercises

###1. Add a surrogate key to flights.

```{r}
flights %>%
  mutate(flight_id = row_number(year)) %>%
  select(flight_id, everything())
```

###2. Identify the keys in the following datasets: 1) Lahman::Batting, 2) babynames::babynames, 3) nasaweather::atmos, 4) fueleconomy::vehicles, 5) ggplot2::diamonds. (You might need to install some packages and read some documentation.)

```{r}
#Lahman::Batting %>% head()
Lahman::Batting %>%
  group_by(playerID, yearID, stint) %>%
  mutate(n = n()) %>%
  filter(n > 1) %>%
  nrow()
```

The primary key for Lahman::Batting is playerID, yearID, stint.

```{r}
#babynames::babynames %>% head()
babynames::babynames %>%
  group_by(year, sex, name) %>%
  mutate(n = n()) %>%
  filter(n > 1) %>%
  nrow()
```

The primary key for babynames::babynames is year, sex, name.

```{r}
#nasaweather::atmos %>% head()
nasaweather::atmos %>%
  group_by(lat, long, year, month) %>%
  mutate(n = n()) %>%
  filter(n > 1) %>%
  nrow()
```

The primary key for nasaweather::atmos is lat, long, year, and month.

```{r}
#fueleconomy::vehicles %>% head()
fueleconomy::vehicles %>%
  group_by(id) %>%
  mutate(n = n()) %>%
  filter(n > 1) %>%
  nrow()
```

The primary key for fueleconomy::vehicles is id. 

```{r}
#ggplot2::diamonds %>% head()
ggplot2::diamonds %>%
  distinct() %>%
  nrow()
nrow(ggplot2::diamonds)
```

There is no primary key for ggplot2::diamonds. The number of distinct rows in the dataset is less than the total number of rows, suggesting that no combination of variables uniquely identifies the observations.

###3. Draw a diagram illustrating the connections between the `Batting`, `Master`, and `Salaries` tables in the Lahman package. Draw another diagram that shows the relationship between `Master`, `Managers`, `AwardsManagers`. How would you characterise the relationship between the `Batting`, `Pitching`, and `Fielding` tables?

```{r}
library(datamodelr)
dm1 <- dm_from_data_frames(list(Batting = Lahman::Batting,
                                Master = Lahman::Master,
                                Salaries = Lahman::Salaries)) %>%
  dm_set_key("Batting", c("playerID", "yearID", "stint")) %>%
  dm_set_key("Master", "playerID") %>%
  dm_set_key("Salaries", c("yearID", "teamID", "playerID")) %>%
  dm_add_references(
    Batting$playerID == Master$playerID,
    Salaries$playerID == Master$playerID
  )

graph1 <- dm_create_graph(dm1, rankdir = "LR", columnArrows = TRUE)
dm_render_graph(graph1)
```

```{r}
library(datamodelr)
dm2 <- dm_from_data_frames(list(Master = Lahman::Master,
                                Managers = Lahman::Managers,
                                AwardsManagers = Lahman::AwardsManagers)) %>%
  dm_set_key("Master", "playerID") %>%
  dm_set_key("Managers", c("yearID", "teamID", "inseason")) %>%
  dm_set_key("AwardsManagers", c("playerID", "awardID", "yearID")) %>%
  dm_add_references(
    Managers$playerID == Master$playerID,
    AwardsManagers$playerID == Master$playerID
  )

graph2 <- dm_create_graph(dm2, rankdir = "LR", columnArrows = TRUE)
dm_render_graph(graph2)
```

`Batting` and `Master` can be matched by playerID. `Salary` can then be matched with `Batting` by playerID and yearID. `Master` and `Managers` can be matched by playerID. `Managers` and `AwardsManagers` can be matched by playerID and yearID.

`Batting`, `Pitching`, and `Fielding` all have a primary key of playerID, yearID, and stint, and have a one-to-one relationship to each other. 

## 13.4.6 Exercises

###1. Compute the average delay by destination, then join on the `airports` data frame so you can show the spatial distribution of delays. Here’s an easy way to draw a map of the United States:

```
airports %>%
  semi_join(flights, c("faa" = "dest")) %>%
  ggplot(aes(lon, lat)) +
    borders("state") +
    geom_point() +
    coord_quickmap()
```

### (Don’t worry if you don’t understand what semi_join() does — you’ll learn about it next.) You might want to use the size or colour of the points to display the average delay for each airport.

```{r}
flights %>% 
  group_by(dest) %>%
  summarize(avg_arr_delay = mean(arr_delay, na.rm = TRUE)) %>%
  left_join(airports, by = c('dest' = 'faa')) %>%
  ggplot(aes(x = lon, y = lat, size = avg_arr_delay, color = avg_arr_delay)) +
  borders('state') +
  geom_point() +
  coord_quickmap()
```

###2. Add the location of the origin and destination (i.e. the `lat` and `lon`) to `flights`.

```{r}
flights %>% 
  left_join(airports, by = c('dest' = 'faa')) %>%
  left_join(airports, by = c('origin' = 'faa'), suffix = c('.dest', '.origin')) %>%
  select(dest, origin, lat.dest, lon.dest, lat.origin, lon.origin)
```

###3. Is there a relationship between the age of a plane and its delays?

```{r}
plane_age <- planes %>%
  mutate(age = 2013 - year) %>%
  select(tailnum, age) %>%
  filter(!is.na(age))

flights %>%
  inner_join(plane_age, by = "tailnum") %>%
  group_by(age) %>%
  filter(!is.na(dep_delay)) %>%
  summarise(delay = mean(dep_delay)) %>%
  ggplot(aes(x = age, y = delay)) +
  geom_point() +
  geom_line()
```

No clear relationship between the age of a plane and its delays - from the plot, delay seems to decrease as the age of the plane increases, but this could be due to other factors as well. 

###4. What weather conditions make it more likely to see a delay?

```{r}
flight_weather <- flights %>%
  inner_join(weather, by = c("origin" = "origin",
                             "year" = "year",
                             "month" = "month",
                             "day" = "day",
                             "hour" = "hour"))
flight_weather %>%
  group_by(precip) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(x = precip, y = delay)) +
  geom_line() + 
  geom_point()

flight_weather %>%
  group_by(wind_speed) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(x = wind_speed, y = delay)) +
  geom_line() + 
  geom_point()

flight_weather %>%
  group_by(humid) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(x = humid, y = delay)) +
  geom_line() + 
  geom_point()
```

Increased windspeed and increased precipitation appear to make it more likely to see a delay. 

###5. What happened on June 13 2013? Display the spatial pattern of delays, and then use Google to cross-reference with the weather.

```{r}
flights %>% 
  filter(year == 2013, month == 6, day == 13) %>%
  group_by(dest) %>%
  summarize(avg_arr_delay = mean(arr_delay, na.rm = TRUE)) %>%
  left_join(airports, by = c('dest' = 'faa')) %>%
  ggplot(aes(x = lon, y = lat, size = avg_arr_delay, color = avg_arr_delay)) +
  borders('state') +
  geom_point(alpha = .5) +
  scale_color_continuous(low = 'yellow', high = 'red') + 
  coord_quickmap()
```

There was a severe storm along the East Coast, resulting in increased delays in those areas. 

## 13.5.1 Exercises

###1. What does it mean for a flight to have a missing `tailnum`? What do the tail numbers that don’t have a matching record in `planes` have in common? (Hint: one variable explains ~90% of the problems.)

```{r}
flights %>%
  anti_join(planes, by = "tailnum") %>%
  count(carrier, sort = TRUE)
```

Many of the flights with tail numbers without a matching record in `planes` have the carrier "MQ" or "AA" - maybe these carriers just don't report tail numbers. 

###2. Filter flights to only show flights with planes that have flown at least 100 flights.

```{r}
flights_100 <- flights %>%
  filter(!is.na(dep_delay)) %>%
  group_by(tailnum) %>%
  summarize(n = n()) %>%
  filter(n > 100)

flights %>%
  semi_join(flights_100, by = 'tailnum')
```

###3. Combine `fueleconomy::vehicles` and `fueleconomy::common` to find only the records for the most common models.

```{r}
fueleconomy::vehicles %>%
  semi_join(fueleconomy::common, by = c('make', 'model'))
```

###4. Find the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the `weather` data. Can you see any patterns?

```{r}
flights_48 <- flights %>%
  group_by(year, month, day) %>%
  summarise(delay_24h = sum(dep_delay, na.rm = TRUE) + sum(arr_delay, na.rm = TRUE)) %>%
  mutate(delay_48h = delay_24h + lag(delay_24h)) %>%
  filter(!(is.na(delay_48h))) %>%
  arrange(desc(delay_48h))

weather_48 <- weather %>%
  group_by(year, month, day) %>%
  summarize_at(vars(humid, precip, temp, visib), mean, na.rm = TRUE)

flights_48 %>%
  left_join(weather_48) %>% 
  head(10) 

flights_48 %>%
  left_join(weather_48) %>% 
  tail(10) 
```

Precipitation and temperature appear to be slightly higher and visibility slightly lower for the worst delays compared to the smallest delays. 

###5. What does `anti_join(flights, airports, by = c("dest" = "faa"))` tell you? What does `anti_join(airports, flights, by = c("faa" = "dest"))` tell you?

```{r}
anti_join(flights, airports, by = c("dest" = "faa"))
```

Gives flights whose destinations are not present in `airports` dataset. 

```{r}
anti_join(airports, flights, by = c("faa" = "dest"))
```

Gives airports that no flights in `flights` dataset are flying to (airports that are not destinations of flights in `flights` dataset). 

###6. You might expect that there’s an implicit relationship between plane and airline, because each plane is flown by a single airline. Confirm or reject this hypothesis using the tools you’ve learned above.

```{r}
flights %>%
  select(carrier, tailnum) %>%
  group_by(tailnum) %>%
  summarize(n = length(unique(carrier))) %>%
  filter(n > 1)
```

Hypothesis rejected - some planes are flown by more than 1 airline. 

## 15.3.1 Exercises

###1. Explore the distribution of `rincome` (reported income). What makes the default bar chart hard to understand? How could you improve the plot?

```{r}
ggplot(gss_cat, aes(rincome)) +
  geom_bar()
```

The default bar chart is hard to understand since the labels on the x axis are too crowded. This can be improved by flipping the x and y axes using `coord_flip()`. 

```{r}
ggplot(gss_cat, aes(rincome)) +
  geom_bar() + 
  coord_flip()
```

###2. What is the most common `relig` in this survey? What’s the most common `partyid`?

```{r}
gss_cat %>%
  count(relig) %>%
  arrange(desc(n)) %>%
  head(1)
```

The most common `relig` in the survey is Protestant.

```{r}
gss_cat %>%
  count(partyid) %>%
  arrange(desc(n)) %>%
  head(1)
```

The most common `partyid` in the survey is Independent.

###3. Which `relig` does `denom` (denomination) apply to? How can you find out with a table? How can you find out with a visualisation?

`denom` applies to `relig` == `Protestant`. 

With a table:
```{r}
gss_cat %>%
  count(relig, denom) %>%
   filter(!denom %in% c("No answer", "Other", "Don't know", "Not applicable", "No denomination")) 
```

With a visualisation: 
```{r}
gss_cat %>%
  count(relig, denom) %>%
  ggplot(aes(relig, denom)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90))
```

## 15.4.1 Exercises

###1. There are some suspiciously high numbers in `tvhours`. Is the mean a good summary?

```{r}
summary(gss_cat[["tvhours"]])
```

No, the median  would likely provide a better summary. 

###2. For each factor in `gss_cat` identify whether the order of the levels is arbitrary or principled.

```{r}
fct_gss <- gss_cat[sapply(gss_cat, is.factor)]
lapply(fct_gss, levels)
```

For `marital`, `race`, `partyid`, `relig`, and `denom`, the order of the levels is arbitrary. For `rincome`, the order lof levels is principled. 

###3. Why did moving “Not applicable” to the front of the levels move it to the bottom of the plot?

Moving "Not applicable" to the front of the levels gives it an integer value of 1.

## 15.5.1 Exercises

###1. How have the proportions of people identifying as Democrat, Republican, and Independent changed over time?

```{r}
levels(gss_cat$partyid)
gss_cat %>%
  mutate(partyid = fct_collapse(partyid, 
  Democrat = c("Not str democrat", "Strong democrat"),
  Republican = c("Strong republican", "Not str republican"),
  Independent = c("Ind,near rep", "Independent", "Ind,near dem"),
  Other = c("No answer", "Don't know", "Other party"))) %>%
  count(year, partyid)  %>%
  group_by(year) %>%
  mutate(p = n / sum(n)) %>%
  ggplot(aes(year, p, group = partyid, color = partyid)) +
    geom_point() +
    geom_line()
```

The number of Independents is increasing, the number of Democrats has fluctuated but overall remains at a steady level, and the number of Republicans is decreasing. 

###2. How could you collapse `rincome` into a small set of categories?

```{r}
gss_cat %>%
  mutate(rincome = fct_collapse(rincome, `Unknown` = c("No answer", "Don't know", "Refused", "Not applicable"),
                                `Lt $5000` = c("Lt $1000", str_c("$", c("1000", "3000", "4000"), " to ", c("2999", "3999", "4999"))),
                                `$5000 to 10000` = str_c("$", c("5000", "6000", "7000", "8000"), " to ", c("5999", "6999", "7999", "9999")))) %>%
  ggplot(aes(rincome)) +
  geom_bar() +
  coord_flip()
```